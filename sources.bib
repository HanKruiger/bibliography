
@article{diefenbach_core_2018,
	title = {Core techniques of question answering systems over knowledge bases: a survey},
	volume = {55},
	issn = {0219-1377, 0219-3116},
	shorttitle = {Core techniques of question answering systems over knowledge bases},
	url = {http://link.springer.com/10.1007/s10115-017-1100-y},
	doi = {10.1007/s10115-017-1100-y},
	abstract = {The Semantic Web contains an enormous amount of information in the form of knowledge bases (KB). To make this information available, many question answering (QA) systems over KBs were created in the last years. Building a QA system over KBs is difﬁcult because there are many different challenges to be solved. In order to address these challenges, QA systems generally combine techniques from natural language processing, information retrieval, machine learning and Semantic Web. The aim of this survey is to give an overview of the techniques used in current QA systems over KBs. We present the techniques used by the QA systems which were evaluated on a popular series of benchmarks: Question Answering over Linked Data (QALD). Techniques that solve the same task are ﬁrst grouped together and then described. The advantages and disadvantages are discussed for each technique. This allows a direct comparison of similar techniques. Additionally, we point to techniques that are used over WebQuestions and SimpleQuestions, which are two other popular benchmarks for QA systems.},
	language = {en},
	number = {3},
	urldate = {2019-04-25},
	journal = {Knowledge and Information Systems},
	author = {Diefenbach, Dennis and Lopez, Vanessa and Singh, Kamal and Maret, Pierre},
	month = jun,
	year = {2018},
	keywords = {semantics, question answering, reading list},
	pages = {529--569}
}

@article{galton_fields_2004,
	title = {Fields and {Objects} in {Space}, {Time}, and {Space}-time},
	volume = {4},
	issn = {1387-5868, 1542-7633},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15427633scc0401_4},
	doi = {10.1207/s15427633scc0401_4},
	abstract = {The well-known distinction between ﬁeld-based and object-based approaches to spatial information is generalised to arbitrary locational frameworks, including in particular space, time and space-time. We systematically explore the different ways in which these approaches can be combined, and address the relative merits of a fully four-dimensional approach as against a more conventional ‘three-plus-one’-dimensional approach. We single out as especially interesting in this respect a class of phenomena, here called multiaspect phenomena, which seem to present different aspects when considered from different points of view. Such phenomena (e.g., ﬂoods, wildﬁres, processions) are proposed as the most natural candidates for treatment as fully four-dimensional entities (‘hyperobjects’), but it remains problematic how to model them so as to do justice to their multi-aspectual nature. The paper ends with a range of important researchable questions aimed at clearing up some of the difﬁculties raised.},
	language = {en},
	number = {1},
	urldate = {2019-04-25},
	journal = {Spatial Cognition \& Computation},
	author = {Galton, Antony},
	month = mar,
	year = {2004},
	keywords = {gim, gis, spatial concepts, reading list},
	pages = {39--68}
}

@book{hitzler_foundations_2010,
	address = {Boca Raton, Fla. London New York},
	series = {Chapman \& {Hall}/{CRC} textbooks in computing},
	title = {Foundations of semantic web technologies},
	isbn = {978-1-4200-9050-5},
	language = {en},
	publisher = {CRC Press},
	author = {Hitzler, Pascal and Krötzsch, Markus and Rudolph, Sebastian},
	year = {2010},
	note = {OCLC: 845661932},
	keywords = {semantics, reading list}
}

@article{krotzsch_description_2012,
	title = {A {Description} {Logic} {Primer}},
	url = {http://arxiv.org/abs/1201.4089},
	abstract = {This paper provides a self-contained ﬁrst introduction to description logics (DLs). The main concepts and features are explained with examples before syntax and semantics of the DL SROIQ are deﬁned in detail. Additional sections review lightweight DL languages, discuss the relationship to the OWL Web Ontology Language and give pointers to further reading.},
	language = {en},
	urldate = {2019-04-25},
	journal = {arXiv:1201.4089 [cs]},
	author = {Krötzsch, Markus and Simancik, Frantisek and Horrocks, Ian},
	month = jan,
	year = {2012},
	note = {arXiv: 1201.4089},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, F.4.1, I.2.4, semantics, description logic, reading list}
}

@inproceedings{lamprecht_synthesis-based_2010,
	address = {Porto, Portugal},
	title = {Synthesis-{Based} {Loose} {Programming}},
	isbn = {978-1-4244-8539-0},
	url = {http://ieeexplore.ieee.org/document/5655574/},
	doi = {10.1109/QUATIC.2010.53},
	abstract = {In this paper we present loose programming, an approach designed to enable process developers to design their application-speciﬁc processes in an intuitive style. Key to this approach is the concept of loose speciﬁcation, a graphical formalism that allows developers to express their processes just by sketching them as kinds of ﬂow graphs without caring about types, precise knowledge about the available process components or the availability of resources. They only have to specify the rough process ﬂow graphically in terms of ontologically deﬁned ‘semantic’ entities. These loose speciﬁcations are then concretized to fully executable process code automatically by means of a combination of 1) data-ﬂow analysis, ensuring the availability of the required resources, 2) temporal logic-based process synthesis, resolving type conﬂicts and taking care of correct component instantiation, and 3) model checking, to ensure global intents and invariants expressed in temporal logic.},
	language = {en},
	urldate = {2019-04-25},
	booktitle = {2010 {Seventh} {International} {Conference} on the {Quality} of {Information} and {Communications} {Technology}},
	publisher = {IEEE},
	author = {Lamprecht, Anna-Lena and Naujokat, Stefan and Margaria, Tiziana and Steffen, Bernhard},
	month = sep,
	year = {2010},
	keywords = {semantics, reading list, workflows},
	pages = {262--267}
}

@book{chrisman_exploring_2002,
	address = {New York},
	edition = {2nd ed},
	title = {Exploring geographic information systems},
	isbn = {978-0-471-31425-7},
	language = {eng},
	publisher = {Wiley},
	author = {Chrisman, Nicholas R.},
	year = {2002},
	note = {OCLC: 833786313},
	keywords = {gis}
}

@book{tomlin_gis_2013,
	address = {Redlands, Calif},
	title = {{GIS} and cartographic modeling},
	isbn = {978-1-58948-309-5},
	language = {eng},
	publisher = {Esri Press},
	author = {Tomlin, C. Dana},
	year = {2013},
	note = {OCLC: 819373309},
	keywords = {gis}
}

@book{longley_geographic_2002,
	address = {Chichester},
	edition = {Repr},
	title = {Geographic information systems and science},
	isbn = {978-0-471-89275-5 978-0-471-49521-5},
	language = {eng},
	publisher = {Wiley},
	editor = {Longley, Paul A.},
	year = {2002},
	note = {OCLC: 248840239},
	keywords = {gis, reading list}
}

@article{falquet_abstract_2018,
	title = {An {Abstract} {Specification} {Technique} for the {Publication} of {Linked} {Geospatial} {Data}},
	abstract = {The publication of linked geodata on the semantic web may involve relatively complex operations to map source data to their published version and to link these ones to other datasets. In this paper we propose a technique to provide a compact and abstract description of this process. This technique is based on the use of RDF graph mapping rules that are expressed in the SPARQL Semantic web query language. We show that such rules are sufficient to express complex mapping and linking operations at a high level, without referring to operations specific to a particular vendor or tool. We also show how this technique applies to a non-trivial use case in the domain of tropical cyclones.},
	language = {en},
	author = {Falquet, Gilles and Métral, Claudine and Ozaine, Sylvain and Giuliani, Gregory},
	year = {2018},
	keywords = {semantics},
	pages = {6}
}

@inproceedings{bao_knowledge-based_2014,
	address = {Baltimore, Maryland},
	title = {Knowledge-{Based} {Question} {Answering} as {Machine} {Translation}},
	url = {http://aclweb.org/anthology/P14-1091},
	doi = {10.3115/v1/P14-1091},
	abstract = {A typical knowledge-based question answering (KB-QA) system faces two challenges: one is to transform natural language questions into their meaning representations (MRs); the other is to retrieve answers from knowledge bases (KBs) using generated MRs. Unlike previous methods which treat them in a cascaded manner, we present a translation-based approach to solve these two tasks in one uniﬁed framework. We translate questions to answers based on CYK parsing. Answers as translations of the span covered by each CYK cell are obtained by a question translation method, which ﬁrst generates formal triple queries as MRs for the span based on question patterns and relation expressions, and then retrieves answers from a given KB based on triple queries generated. A linear model is deﬁned over derivations, and minimum error rate training is used to tune feature weights based on a set of question-answer pairs. Compared to a KB-QA system using a state-of-the-art semantic parser, our method achieves better results.},
	language = {en},
	urldate = {2019-04-25},
	booktitle = {Proceedings of the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Bao, Junwei and Duan, Nan and Zhou, Ming and Zhao, Tiejun},
	year = {2014},
	keywords = {question answering, reading list},
	pages = {967--976}
}

@book{de_bellefon_handbook_2018,
	title = {Handbook of {Spatial} {Analysis}},
	author = {de Bellefon, Marie-Pierre},
	year = {2018}
}

@article{simmons_natural_1970,
	title = {Natural language question-answering systems: 1969},
	volume = {13},
	issn = {00010782},
	shorttitle = {Natural language question-answering systems},
	url = {http://portal.acm.org/citation.cfm?doid=361953.361963},
	doi = {10.1145/361953.361963},
	language = {en},
	number = {1},
	urldate = {2019-04-25},
	journal = {Communications of the ACM},
	author = {Simmons, Robert F.},
	month = jan,
	year = {1970},
	pages = {15--30}
}

@incollection{woods_semantics_1978,
	title = {Semantics and {Quantification} in {Natural} {Language} {Question} {Answering}},
	volume = {17},
	isbn = {978-0-12-012117-5},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0065245808603903},
	language = {en},
	urldate = {2019-04-25},
	booktitle = {Advances in {Computers}},
	publisher = {Elsevier},
	author = {Woods, W.A.},
	year = {1978},
	doi = {10.1016/S0065-2458(08)60390-3},
	keywords = {semantics, question answering, reading list},
	pages = {1--87}
}

@incollection{baader_basic_2007,
	address = {Cambridge},
	edition = {2},
	title = {Basic {Description} {Logics}},
	isbn = {978-0-511-71178-7},
	url = {https://www.cambridge.org/core/product/identifier/CBO9780511711787A022/type/book_part},
	abstract = {This chapter provides an introduction to Description Logics as a formal language for representing knowledge and reasoning about it. It ﬁrst gives a short overview of the ideas underlying Description Logics. Then it introduces syntax and semantics, covering the basic constructors that are used in systems or have been introduced in the literature, and the way these constructors can be used to build knowledge bases. Finally, it deﬁnes the typical inference problems, shows how they are interrelated, and describes diﬀerent approaches for eﬀectively solving these problems. Some of the topics that are only brieﬂy mentioned in this chapter will be treated in more detail in subsequent chapters.},
	language = {en},
	urldate = {2019-04-26},
	booktitle = {The {Description} {Logic} {Handbook}},
	publisher = {Cambridge University Press},
	author = {Baader, F. and Nutt, W.},
	editor = {Baader, Franz and Calvanese, Diego and McGuinness, Deborah L. and Nardi, Daniele and Patel-Schneider, Peter F.},
	year = {2007},
	doi = {10.1017/CBO9780511711787.004},
	keywords = {description logic},
	pages = {47--104}
}

@incollection{groth_cubeqaquestion_2016,
	address = {Cham},
	title = {{CubeQA}—{Question} {Answering} on {RDF} {Data} {Cubes}},
	volume = {9981},
	isbn = {978-3-319-46522-7 978-3-319-46523-4},
	url = {http://link.springer.com/10.1007/978-3-319-46523-4_20},
	abstract = {Statistical data in the form of RDF Data Cubes is becoming increasingly valuable as it inﬂuences decisions in areas such as health care, policy and ﬁnance. While a growing amount is becoming freely available through the open data movement, this data is opaque to laypersons. Semantic Question Answering (SQA) technologies provide intuitive access via free-form natural language queries but general SQA systems cannot process RDF Data Cubes. On the intersection between RDF Data Cubes and SQA, we create a new subﬁeld of SQA, called RDCQA. We create an RDQCA benchmark as task 3 of the QALD-6 evaluation challenge, to stimulate further research and enable quantitative comparison between RDCQA systems. We design and evaluate the domain independent CubeQA algorithm, which is the ﬁrst RDCQA system and achieves a global F1 score of 0.43 on the QALD6T3-test benchmark, showing that RDCQA is feasible.},
	language = {en},
	urldate = {2019-04-29},
	booktitle = {The {Semantic} {Web} – {ISWC} 2016},
	publisher = {Springer International Publishing},
	author = {Höffner, Konrad and Lehmann, Jens and Usbeck, Ricardo},
	editor = {Groth, Paul and Simperl, Elena and Gray, Alasdair and Sabou, Marta and Krötzsch, Markus and Lecue, Freddy and Flöck, Fabian and Gil, Yolanda},
	year = {2016},
	doi = {10.1007/978-3-319-46523-4_20},
	pages = {325--340}
}

@misc{hitzler_owl_2012,
	title = {{OWL} 2 {Web} {Ontology} {Language} {Primer} ({Second} {Edition})},
	url = {https://www.w3.org/TR/owl2-primer/},
	urldate = {2019-04-29},
	author = {Hitzler, Pascal and Krötzsch, Markus and Parsia, Bijan and Patel-Schneider, Peter F. and Rudolph, Sebastian},
	year = {2012},
	keywords = {semantics}
}

@mastersthesis{svalastoga_use_2014,
	title = {Use of {Syntax} in {Question} {Answering} {Tasks}},
	school = {University of Oslo},
	author = {Svalastoga, Marte},
	year = {2014},
	keywords = {question answering}
}

@misc{scheider_simon_question-based_2018,
	title = {Question-based {Analysis} of {Geographic} {Information} with {Semantic} {Queries}},
	language = {en},
	author = {Scheider, Simon},
	year = {2018},
	keywords = {grant proposal}
}

@article{davis_commonsense_2015,
	title = {Commonsense reasoning and commonsense knowledge in artificial intelligence},
	volume = {58},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=2817191.2701413},
	doi = {10.1145/2701413},
	language = {en},
	number = {9},
	urldate = {2019-04-30},
	journal = {Communications of the ACM},
	author = {Davis, Ernest and Marcus, Gary},
	month = aug,
	year = {2015},
	pages = {92--103}
}

@article{lipton_mythos_2016,
	title = {The {Mythos} of {Model} {Interpretability}},
	url = {http://arxiv.org/abs/1606.03490},
	abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspeciﬁed. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to reﬁne the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, ﬁnding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
	language = {en},
	urldate = {2019-04-30},
	journal = {arXiv:1606.03490 [cs, stat]},
	author = {Lipton, Zachary C.},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.03490},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, gim}
}

@misc{dibiase_is_2018,
	title = {Is {GIScience} converging with {Data} {Science}? {Shou}... {\textbar} {GeoNet}},
	url = {https://community.esri.com/community/education/blog/2018/05/05/is-giscience-converging-with-data-science-should-it},
	urldate = {2019-04-30},
	author = {DiBiase, David},
	year = {2018},
	keywords = {gim, to read}
}

@article{arribas-bel_geography_2018,
	title = {Geography and computers: {Past}, present, and future},
	volume = {12},
	issn = {17498198},
	shorttitle = {Geography and computers},
	url = {http://doi.wiley.com/10.1111/gec3.12403},
	doi = {10.1111/gec3.12403},
	abstract = {The discipline of Geography has long been intertwined with the use of computers. This close interaction is likely to increase with the embeddedness of computers and concomitant growth of spatially referenced data. To better understand the current situation, and to be able to better speculate about the future, this article provides two parallel perspectives: first, we offer an historical perspective on the relationship between Geography and computers; second, we document developments—in particular the nascent field of data science—that are currently taking place outside of Geography and to which we argue the discipline should be paying close attention. Combining both perspectives, we identify the benefits of tighter integration between Geography and Data Science and argue for the establishment of a new space—that we term Geographic Data Science—in which cross‐pollination could occur to the benefit of both Geography and the larger data community.},
	language = {en},
	number = {10},
	urldate = {2019-04-30},
	journal = {Geography Compass},
	author = {Arribas-Bel, Dani and Reades, Jon},
	month = oct,
	year = {2018},
	keywords = {gim, to read},
	pages = {e12403}
}

@inproceedings{scheider_semantic_2019,
	title = {Semantic data type signatures for representing spatial core concepts in {GIS} operations on spatial layers},
	author = {Scheider, Simon},
	year = {2019},
	keywords = {rejected, gis, semantics, check references, reading list}
}

@inproceedings{egenhofer_toward_2002,
	address = {McLean, Virginia, USA},
	title = {Toward the semantic geospatial web},
	isbn = {978-1-58113-591-6},
	url = {http://portal.acm.org/citation.cfm?doid=585147.585148},
	doi = {10.1145/585147.585148},
	abstract = {With the growth of the World Wide Web has come the insight that currently available methods for finding and using information on the web are often insufficient. In order to move the Web from a data repository to an information resource, a totally new way of organizing information is needed. The advent of the Semantic Web promises better retrieval methods by incorporating the data’s semantics and exploiting the semantics during the search process. Such a development needs special attention from the geospatial perspective so that the particularities of geospatial meaning are captured appropriately. The creation the Semantic Geospatial Web needs the development multiple spatial and terminological ontologies, each with a formal semantics; the representation of those semantics such that they are available both to machines for processing and to people for understanding; and the processing of geospatial queries against these ontologies and the evaluation of the retrieval results based on the match between the semantics of the expressed information need and the available semantics of the information resources and search systems. This will lead to a new framework for geospatial information retrieval based on the semantics of spatial and terminological ontologies. By explicitly representing the role of semantics in different components of the information retrieval process (people, interfaces, search systems, and information resources), the Semantic Geospatial Web will enable users to retrieve more precisely the data they need, based on the semantics associated with these data.},
	language = {en},
	urldate = {2019-04-30},
	booktitle = {Proceedings of the tenth {ACM} international symposium on {Advances} in geographic information systems  - {GIS} '02},
	publisher = {ACM Press},
	author = {Egenhofer, Max J.},
	year = {2002},
	keywords = {semantics, to read},
	pages = {1--4}
}

@article{scheider_using_2017,
	title = {Using {SPARQL} to describe {GIS} methods in terms of the questions they answer},
	abstract = {GIS methods consist of computational and analytic tools applied to data in order to answer a specific question. For example, in which way is the social wellbeing of a city different from its surroundings? Or, in how far is the surrounding population affected by road construction? The first question may be answered e.g. by constructing a choropleth map, the second one by an area interpolation. In order to effectively search and reuse such GIS methods over the Web, it is necessary to describe them in terms of the questions they answer, not only in terms of particular software or data types. This requires a way to match requests to methods, where both are described in terms of queries about a geographic subject matter, as envisioned in previous work on Datalog based geoservice chaining. However, to truly cover GIS methods, we argue that a much more expressive interrogative Web language is needed, which allows querying over relations and classes and includes completion statements. In this paper, we explain why and discuss in how far SPARQL query containment might be a suitable approach to this end.},
	language = {en},
	author = {Scheider, Simon and Lemmens, Rob},
	year = {2017},
	keywords = {gis, semantics, to read, question answering},
	pages = {6}
}

@incollection{hutchison_geospatial_2005,
	address = {Berlin, Heidelberg},
	title = {Geospatial {Semantics}: {Why}, of {What}, and {How}?},
	volume = {3534},
	isbn = {978-3-540-26225-1 978-3-540-31551-3},
	shorttitle = {Geospatial {Semantics}},
	url = {http://link.springer.com/10.1007/11496168_1},
	abstract = {Why are notions like semantics and ontologies suddenly getting so much attention, within and outside geospatial information communities? The main reason lies in the componentization of Geographic Information Systems (GIS) into services, which are supposed to interoperate within and across these communities. Consequently, I look at geospatial semantics in the context of semantic interoperability. The paper clarifies the relevant notion of semantics and shows what parts of geospatial information need to receive semantic specifications in order to achieve interoperability. No attempt at a survey of approaches to provide semantics is made, but a framework for solving interoperability problems is proposed in the form of semantic reference systems. Particular emphasis is put on the need and possible ways to ground geospatial semantics in physical processes and measurements.},
	language = {en},
	urldate = {2019-04-30},
	booktitle = {Journal on {Data} {Semantics} {III}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kuhn, Werner},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Spaccapietra, Stefano and Zimányi, Esteban},
	year = {2005},
	doi = {10.1007/11496168_1},
	keywords = {semantics},
	pages = {1--24}
}

@article{kuhn_core_2012,
	title = {Core concepts of spatial information for transdisciplinary research},
	volume = {26},
	issn = {1365-8816, 1362-3087},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13658816.2012.722637},
	doi = {10.1080/13658816.2012.722637},
	language = {en},
	number = {12},
	urldate = {2019-04-30},
	journal = {International Journal of Geographical Information Science},
	author = {Kuhn, Werner},
	month = dec,
	year = {2012},
	keywords = {spatial concepts, reading list},
	pages = {2267--2276}
}

@incollection{gangemi_ontology_2009,
	title = {Ontology {Design} {Patterns}},
	booktitle = {Handbook on {Ontologies}},
	author = {Gangemi, Aldo and Presutti, Valentina},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_10},
	keywords = {semantics},
	pages = {221--243}
}

@article{scheider_exploratory_2016,
	title = {Exploratory querying of {SPARQL} endpoints in space and time},
	volume = {8},
	issn = {22104968, 15700844},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-150211},
	doi = {10.3233/SW-150211},
	abstract = {The linked data Web provides a simple and ﬂexible way of accessing information resources in a self-descriptive format. This offers a realistic chance of perforating existing data silos. However, in order to do so, space, time and other semantic concepts need to function as dimensions for effectively exploring, querying and ﬁltering contents. While triple stores, SPARQL endpoints, and RDF were designed for machine access, large burdens are still placed on a user to simultaneously explore and query the contents of a given endpoint according to these dimensions. First, one has to know the semantic concepts and the type of knowledge contained in an endpoint a-priori in order to query content effectively. Second, one has to be able to write and understand SPARQL and RDF. And third, one has to understand complex data type literals for space and time. In this article, we propose a way to deal with these challenges by interactive visual query construction, i.e., by letting query results feedback into both (space-time) exploration and ﬁltering, and thus enabling exploratory querying. We propose design principles for SPEX (Spatio-temporal content explorer), a tool which helps people unfamiliar with the content of SPARQL endpoints or their syntax to explore the latter in space and time. In a preliminary user study on a repository of historical maps, we found that our feedback principles were effective, however, that successful question answering still requires improvements regarding space-time ﬁltering, vocabulary explanation and the linking of space-time windows with other displays.},
	language = {en},
	number = {1},
	urldate = {2019-04-30},
	journal = {Semantic Web},
	author = {Scheider, Simon and Degbelo, Auriol and Lemmens, Rob and van Elzakker, Corné and Zimmerhof, Peter and Kostic, Nemanja and Jones, Jim and Banhatti, Gautam},
	editor = {Dadzie, Aba-Sah and Pietriga, Emmanuel and Dadzie, Aba-Sah and Pietriga, Emmanuel},
	month = nov,
	year = {2016},
	keywords = {to read},
	pages = {65--86}
}

@book{noauthor_marklogic_2017,
	title = {{MarkLogic} {Server}: {Search} {Developer}’s {Guide}},
	language = {en},
	year = {2017}
}

@book{noauthor_marklogic_2017-1,
	title = {{MarkLogic} {Server}: {Semantics} {Developer}’s {Guide}},
	language = {en},
	year = {2017}
}

@book{noauthor_marklogic_2017-2,
	title = {{MarkLogic} {Server}: {REST} {Application} {Developer}’s {Guide}},
	language = {en},
	year = {2017}
}

@article{scheider_frames_2019,
	title = {Frames of reference in environmental narratives},
	abstract = {In order to transform locative expressions contained in narrative texts to coordinate systems in a GIS, it is necessary to identify the diﬀerent types of cognitive frames of reference (FoR) used within parts of speech (PoS). In this abstract, I illustrate this challenge based on an example of a mountaineering text.},
	language = {en},
	author = {Scheider, Simon},
	year = {2019},
	pages = {4}
}

@article{scheider_knowing_2016,
	title = {Knowing {Whether} {Spatio}-{Temporal} {Analysis} {Procedures} {Are} {Applicable} to {Datasets}},
	copyright = {©2016 \&copy; The authors and IOS Press.},
	issn = {0922-6389},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospressISBN&isbn=978-1-61499-659-0&spage=67&doi=10.3233/978-1-61499-660-6-67},
	doi = {10.3233/978-1-61499-660-6-67},
	abstract = {How can data analysts identify spatio-temporal datasets that are suitable for their task? Answering this question is not only dependent on the aim of the analysis and the semantic contents of the data, but also on knowing whether the required data combinations and transformations, spatio-temporal analysis methods, charts and map visualizations are meaningfully applicable to the data. Operators need to assess whether they can meaningfully apply analytical operations to data to derive the information required. Answering this question in a general and computationally executable way is a crucial step on our way towards supporting data analysts and their research practice in e-Science. We propose an ontology design pattern for spatio-temporal information that enables to reason about the applicability of a number of fundamental classes of analyses in relation to given data, i.e., whether data sets can be compared, transformed, combined, and whether summary statistics can be applied to them. We demonstrate this ontology implemented in OWL through a set of corresponding SPARQL queries applied to meta-data of datasets from the AURIN portal.},
	language = {en},
	urldate = {2019-05-06},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Scheider, Simon and Martin, Tomko},
	year = {2016},
	pages = {67--80}
}

@article{albrecht_universal_1998,
	title = {Universal analytical {GIS} operations — a task-oriented systematization of data structure-independent {GIS} functionality},
	abstract = {The few existing taxonomies of analytical GIS operations are limited either by the data structure that they are based on - or by the scope of applications for which they had been developed. They are not formalized and do not attempt to be truly universal. This paper tackles these deficiencies with a user survey to determine user expectations of a GIS' functionality. The result is a list of only 20 universal analytical GIS operations that allow to build all but the most exotic GIS applications.},
	language = {en},
	author = {Albrecht, Jochen},
	year = {1998},
	keywords = {reading list},
	pages = {18}
}

@incollection{bacao_designing_2015,
	address = {Cham},
	title = {Designing a {Language} for {Spatial} {Computing}},
	isbn = {978-3-319-16786-2 978-3-319-16787-9},
	url = {http://link.springer.com/10.1007/978-3-319-16787-9_18},
	abstract = {We present the design rationale underlying a language for spatial computing and sketch a prototypical implementation in Python. The goal of this work is to provide a high-level language for spatial computing that is executable on existing commercial and open source spatial computing platforms, particularly Geographic Information Systems (GIS). The key idea of the approach is to target an abstraction level higher than that of GIS commands and data formats, yet meaningful within and across application domains. The paper describes the underlying theory of spatial information and shows its evolving formal specification. An embedding in Python exemplifies access to commonly available implementations of spatial computations.},
	language = {en},
	urldate = {2019-05-07},
	booktitle = {{AGILE} 2015},
	publisher = {Springer International Publishing},
	author = {Kuhn, Werner and Ballatore, Andrea},
	editor = {Bacao, Fernando and Santos, Maribel Yasmina and Painho, Marco},
	year = {2015},
	doi = {10.1007/978-3-319-16787-9_18},
	keywords = {reading list},
	pages = {309--326}
}

@article{scheider_semantic_2018,
	title = {Semantic typing of linked geoprocessing workflows},
	volume = {11},
	issn = {1753-8947, 1753-8955},
	url = {https://www.tandfonline.com/doi/full/10.1080/17538947.2017.1305457},
	doi = {10.1080/17538947.2017.1305457},
	language = {en},
	number = {1},
	urldate = {2019-05-07},
	journal = {International Journal of Digital Earth},
	author = {Scheider, Simon and Ballatore, Andrea},
	month = jan,
	year = {2018},
	keywords = {reading list},
	pages = {113--138}
}

@article{scheider_finding_2019,
	title = {Finding and sharing {GIS} methods based on the questions they answer},
	volume = {12},
	issn = {1753-8947, 1753-8955},
	url = {https://www.tandfonline.com/doi/full/10.1080/17538947.2018.1470688},
	doi = {10.1080/17538947.2018.1470688},
	abstract = {Geographic information has become central for data scientists of many disciplines to put their analyzes into a spatio-temporal perspective. However, just as the volume and variety of data sources on the Web grow, it becomes increasingly harder for analysts to be familiar with all the available geospatial tools, including toolboxes in Geographic Information Systems (GIS), R packages, and Python modules. Even though the semantics of the questions answered by these tools can be broadly shared, tools and data sources are still divided by syntax and platform-specific technicalities. It would, therefore, be hugely beneficial for information science if analysts could simply ask questions in generic and familiar terms to obtain the tools and data necessary to answer them. In this article, we systematically investigate the analytic questions that lie behind a range of common GIS tools, and we propose a semantic framework to match analytic questions and tools that are capable of answering them. To support the matching process, we define a tractable subset of SPARQL, the query language of the Semantic Web, and we propose and test an algorithm for computing query containment. We illustrate the identification of tools to answer user questions on a set of common user requests.},
	language = {en},
	number = {5},
	urldate = {2019-05-07},
	journal = {International Journal of Digital Earth},
	author = {Scheider, S. and Ballatore, A. and Lemmens, R.},
	month = may,
	year = {2019},
	keywords = {reading list},
	pages = {594--613}
}

@article{scheider_modeling_2016,
	title = {Modeling spatiotemporal information generation},
	issn = {1365-8816, 1362-3087},
	url = {http://www.tandfonline.com/doi/full/10.1080/13658816.2016.1151520},
	doi = {10.1080/13658816.2016.1151520},
	abstract = {Maintaining knowledge about the provenance of datasets, that is, about how they were obtained, is crucial for their further use. Contrary to what the overused metaphors of ‘data mining’ and ‘big data’ are implying, it is hardly possible to use data in a meaningful way if information about sources and types of conversions is discarded in the process of data gathering. A generative model of spatiotemporal information could not only help automating the description of derivation processes but also assessing the scope of a dataset’s future use by exploring possible transformations. Even though there are technical approaches to document data provenance, models for describing how spatiotemporal data are generated are still missing. To ﬁll this gap, we introduce an algebra that models data generation and describes how datasets are derived, in terms of types of reference systems. We illustrate its versatility by applying it to a number of derivation scenarios, ranging from ﬁeld aggregation to trajectory generation, and discuss its potential for retrieval, analysis support systems, as well as for assessing the space of meaningful computations.},
	language = {en},
	urldate = {2019-05-07},
	journal = {International Journal of Geographical Information Science},
	author = {Scheider, Simon and Gräler, Benedikt and Pebesma, Edzer and Stasch, Christoph},
	month = mar,
	year = {2016},
	keywords = {reading list},
	pages = {1--29}
}

@incollection{sarjakoski_question-based_2016,
	address = {Cham},
	title = {Question-{Based} {Spatial} {Computing}—{A} {Case} {Study}},
	isbn = {978-3-319-33782-1 978-3-319-33783-8},
	url = {http://link.springer.com/10.1007/978-3-319-33783-8_3},
	abstract = {Geographic Information Systems (GIS) support spatial problem solving by large repositories of procedures, which are mainly operating on map layers. These procedures and their parameters are often not easy to understand and use, especially not for domain experts without extensive GIS training. This hinders a wider adoption of mapping and spatial analysis across disciplines. Building on the idea of core concepts of spatial information, and further developing the language for spatial computing based on them, we introduce an alternative approach to spatial analysis, based on the idea that users should be able to ask questions about the environment, rather than ﬁnding and executing procedures on map layers. We deﬁne such questions in terms of the core concepts of spatial information, and use data abstraction instead of procedural abstraction to structure command spaces for application programmers (and ultimately for end users). We sketch an implementation in Python that enables application programmers to dispatch computations to existing GIS capabilities. The gains in usability and conceptual clarity are illustrated through a case study from economics, comparing a traditional procedural solution with our declarative approach. The case study shows a reduction of computational steps by around 45\%, as well as smaller and better organized command spaces.},
	language = {en},
	urldate = {2019-05-07},
	booktitle = {Geospatial {Data} in a {Changing} {World}},
	publisher = {Springer International Publishing},
	author = {Vahedi, Behzad and Kuhn, Werner and Ballatore, Andrea},
	editor = {Sarjakoski, Tapani and Santos, Maribel Yasmina and Sarjakoski, L. Tiina},
	year = {2016},
	doi = {10.1007/978-3-319-33783-8_3},
	keywords = {reading list},
	pages = {37--50}
}

@article{janowicz_why_2015,
	title = {Why the {Data} {Train} {Needs} {Semantic} {Rails}},
	volume = {36},
	issn = {0738-4602, 0738-4602},
	url = {https://aaai.org/ojs/index.php/aimagazine/article/view/2560},
	doi = {10.1609/aimag.v36i1.2560},
	abstract = {While catchphrases such as big data, smart data, dataintensive science, or smart dust highlight different aspects, they share a common theme: Namely, a shift towards a data-centric perspective in which the synthesis and analysis of data at an ever-increasing spatial, temporal, and thematic resolution promises new insights, while, at the same time, reducing the need for strong domain theories as starting points. In terms of the envisioned methodologies, those catchphrases tend to emphasize the role of predictive analytics, i.e., statistical techniques including data mining and machine learning, as well as supercomputing. Interestingly, however, while this perspective takes the availability of data as a given, it does not answer the question how one would discover the required data in today’s chaotic information universe, how one would understand which datasets can be meaningfully integrated, and how to communicate the results to humans and machines alike. The Semantic Web addresses these questions. In the following, we argue why the data train needs semantic rails. We point out that making sense of data and gaining new insights works best if inductive and deductive techniques go hand-in-hand instead of competing over the prerogative of interpretation.},
	language = {en},
	number = {1},
	urldate = {2019-05-07},
	journal = {AI Magazine},
	author = {Janowicz, Krzysztof and Van Harmelen, Frank and Hendler, James A. and Hitzler, Pascal},
	month = mar,
	year = {2015},
	keywords = {reading list},
	pages = {5}
}

@incollection{gervasi_constraints-driven_2016,
	address = {Cham},
	title = {Constraints-{Driven} {Automatic} {Geospatial} {Service} {Composition}: {Workflows} for the {Analysis} of {Sea}-{Level} {Rise} {Impacts}},
	volume = {9788},
	isbn = {978-3-319-42110-0 978-3-319-42111-7},
	shorttitle = {Constraints-{Driven} {Automatic} {Geospatial} {Service} {Composition}},
	url = {http://link.springer.com/10.1007/978-3-319-42111-7_12},
	abstract = {Building applications based on the reuse of existing components or services has noticeably increased in the geospatial application domain, but researchers still face a variety of technical challenges designing workﬂows for their speciﬁc objectives and preferences. Hence, means for automatic service composition that provide semantics-based assistance in the workﬂow design process have become a frequent demand especially of end users who are not IT experts. This paper presents a method for automatic composition of workﬂows for analyzing the impacts of sea-level rise based on semantic domain modeling. The domain modeling comprises the design of adequate services, the deﬁnition of ontologies to provide domain-speciﬁc vocabulary for referring to types and services, and the input/output annotation of the services using the terms deﬁned in the ontologies. We use the PROPHETS plugin of the jABC workﬂow framework to show how users can beneﬁt from such a domain model when they apply its constraintsdriven synthesis methods to obtain the workﬂows that match their intentions.},
	language = {en},
	urldate = {2019-05-07},
	booktitle = {Computational {Science} and {Its} {Applications} -- {ICCSA} 2016},
	publisher = {Springer International Publishing},
	author = {Al-Areqi, Samih and Lamprecht, Anna-Lena and Margaria, Tiziana},
	editor = {Gervasi, Osvaldo and Murgante, Beniamino and Misra, Sanjay and Rocha, Ana Maria A.C. and Torre, Carmelo M. and Taniar, David and Apduhan, Bernady O. and Stankova, Elena and Wang, Shangguang},
	year = {2016},
	doi = {10.1007/978-3-319-42111-7_12},
	keywords = {reading list, workflows},
	pages = {134--150}
}

@article{gil_examining_2007,
	title = {Examining the {Challenges} of {Scientific} {Workflows}},
	volume = {40},
	issn = {0018-9162},
	url = {http://ieeexplore.ieee.org/document/4404805/},
	doi = {10.1109/MC.2007.421},
	abstract = {Workflows have recently emerged as a paradigm for representing and managing complex distributed scientific computations and therefore accelerate the pace of scientific progress. A recent workshop on the Challenges of Scientific Workflows, sponsored by the National Science Foundation and held on May 1-2, 2006, brought together domain scientists, computer scientists, and social scientists to discuss requirements of future scientific applications and the challenges that they present to current workflow technologies. This paper reports on the discussions and recommendations of the workshop, the full report can be found at http://www.isi.edu/nsf-workflows06.},
	language = {en},
	number = {12},
	urldate = {2019-05-07},
	journal = {Computer},
	author = {Gil, Yolanda and Deelman, Ewa and Ellisman, Mark and Fahringer, Thomas and Fox, Geoffrey and Gannon, Dennis and Goble, Carole and Livny, Miron and Moreau, Luc and Myers, Jim},
	month = dec,
	year = {2007},
	keywords = {reading list, workflows},
	pages = {24--32}
}

@article{king_formalization_2011,
	title = {On the formalization and reuse of scientific research},
	volume = {8},
	issn = {1742-5689, 1742-5662},
	url = {http://rsif.royalsocietypublishing.org/cgi/doi/10.1098/rsif.2011.0029},
	doi = {10.1098/rsif.2011.0029},
	language = {en},
	number = {63},
	urldate = {2019-05-07},
	journal = {Journal of The Royal Society Interface},
	author = {King, R. D. and Liakata, M. and Lu, C. and Oliver, S. G. and Soldatova, L. N.},
	month = oct,
	year = {2011},
	keywords = {reading list, workflows},
	pages = {1440--1448}
}

@inproceedings{naujokat_tailoring_2011,
	address = {Las Vegas, NV, USA},
	title = {Tailoring {Process} {Synthesis} to {Domain} {Characteristics}},
	isbn = {978-1-61284-853-2},
	url = {http://ieeexplore.ieee.org/document/5773391/},
	doi = {10.1109/ICECCS.2011.24},
	abstract = {PROPHETS is our ﬂexible framework for the synthesis of processes from libraries of basic services. In this paper we demonstrate how its synthesis strategy can be tailored to the considered application domain. For this purpose, PROPHETS provides a number of conﬁguration options, such as different data exchange formats (e.g. shared variables and pipelining) for the resulting process, as well as structural and temporal logic constraints for minimizing the inherent search space. We illustrate the impact of adequate synthesis tailoring by contrasting two real-life case studies with diametric characteristics.},
	language = {en},
	urldate = {2019-05-07},
	booktitle = {2011 16th {IEEE} {International} {Conference} on {Engineering} of {Complex} {Computer} {Systems}},
	publisher = {IEEE},
	author = {Naujokat, Stefan and Lamprecht, Anna-Lena and Steffen, Bernhard},
	month = apr,
	year = {2011},
	keywords = {reading list, workflows},
	pages = {167--175}
}

@book{kraak_cartography:_2010,
	address = {Harlow},
	edition = {3. ed},
	title = {Cartography: visualization of geospatial data},
	isbn = {978-0-273-72279-3},
	shorttitle = {Cartography},
	language = {eng},
	publisher = {Prentice Hall},
	author = {Kraak, Menno-Jan and Ormeling, Ferjan},
	year = {2010},
	note = {OCLC: 845616878},
	keywords = {reading list}
}

@article{ballatore_geographic_2013,
	title = {Geographic knowledge extraction and semantic similarity in {OpenStreetMap}},
	volume = {37},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-012-0571-0},
	doi = {10.1007/s10115-012-0571-0},
	abstract = {In recent years a web phenomenon known as Volunteered Geographic Information (VGI) has produced large crowdsourced geographic datasets. OpenStreetMap (OSM), the leading VGI project, aims at building an open-content world map through user contributions. OSM semantics consists of a set of properties (called ‘tags’) describing geographic classes, whose usage is deﬁned by project contributors on a dedicated Wiki website. Because of its simple and open semantic structure, the OSM approach often results in noisy and ambiguous data, limiting its usability for analysis in information retrieval, recommender systems, and data mining. Devising a mechanism for computing the semantic similarity of the OSM geographic classes can help alleviate this semantic gap. The contribution of this paper is twofold. It consists of (i) the development of the OSM Semantic Network by means of a web crawler tailored to the OSM Wiki website; this semantic network can be used to compute semantic similarity through co-citation measures, providing a novel semantic tool for OSM and GIS communities; (ii) a study of the cognitive plausibility (i.e. the ability to replicate human judgement) of co-citation algorithms when applied to the computation of semantic similarity of geographic concepts. Empirical evidence supports the usage of co-citation algorithms – SimRank showing the highest plausibility – to compute concept similarity in a crowdsourced semantic network.},
	language = {en},
	number = {1},
	urldate = {2019-05-09},
	journal = {Knowledge and Information Systems},
	author = {Ballatore, Andrea and Bertolotto, Michela and Wilson, David C.},
	month = oct,
	year = {2013},
	keywords = {semantics, osm},
	pages = {61--81}
}

@incollection{fabrikant_what_2015,
	address = {Cham},
	title = {What is in a {Contour} {Map}?},
	volume = {9368},
	isbn = {978-3-319-23373-4 978-3-319-23374-1},
	url = {http://link.springer.com/10.1007/978-3-319-23374-1_18},
	abstract = {Contours maps (such as topographic maps) compress the information of a function over a two-dimensional area into a discrete set of closed lines that connect points of equal value (isolines), striking a ﬁne balance between expressiveness and cognitive simplicity. They allow humans to perform many common sense reasoning tasks about the underlying function (e.g. elevation).},
	language = {en},
	urldate = {2019-05-13},
	booktitle = {Spatial {Information} {Theory}},
	publisher = {Springer International Publishing},
	author = {Hahmann, Torsten and Usery, E. Lynn},
	editor = {Fabrikant, Sara Irina and Raubal, Martin and Bertolotto, Michela and Davies, Clare and Freundschuh, Scott and Bell, Scott},
	year = {2015},
	doi = {10.1007/978-3-319-23374-1_18},
	pages = {375--399}
}

@article{berners-lee_semantic_2001,
	title = {The {Semantic} {Web}},
	journal = {Scientific American},
	author = {Berners-Lee, Tim and Hendler, James A. and Lassila, A.},
	month = may,
	year = {2001},
	pages = {96--101}
}

@book{worboys_gis_1995,
	address = {London; Bristol, PA},
	title = {{GIS}, a computing perspective},
	isbn = {9786610405442},
	url = {http://ezproxy.usherbrooke.ca/login?url=http://www.myilibrary.com?id=40544},
	language = {English},
	urldate = {2019-05-16},
	publisher = {Taylor \& Francis},
	author = {Worboys, Michael},
	year = {1995},
	note = {OCLC: 1083982423},
	keywords = {gis, reading list}
}

@article{haklay_openstreetmap:_2008,
	title = {{OpenStreetMap}: {User}-{Generated} {Street} {Maps}},
	volume = {7},
	issn = {1536-1268},
	shorttitle = {{OpenStreetMap}},
	url = {http://ieeexplore.ieee.org/document/4653466/},
	doi = {10.1109/MPRV.2008.80},
	language = {en},
	number = {4},
	urldate = {2019-05-23},
	journal = {IEEE Pervasive Computing},
	author = {Haklay, M. and Weber, P.},
	month = oct,
	year = {2008},
	pages = {12--18}
}

@inproceedings{scheider_geo-analytical_2019,
	title = {Geo-{Analytical} {Question}-{Answering} with {GIS}: {The} role of spatial concepts},
	language = {en},
	author = {Scheider, Simon},
	year = {2019},
	keywords = {gis, spatial concepts, question answering, draft, to review},
	pages = {8}
}

@misc{sinton_inherent_nodate,
	title = {The inherent structure of information as a constraint to analysis mapped thematic data as a case study},
	author = {Sinton, David F.},
	keywords = {to read}
}

@book{gil_semantic_2005,
	address = {Berlin},
	series = {Lecture notes in computer science},
	title = {The {Semantic} {Web} - {ISWC} 2005: 4th {International} {Semantic} {Web} {Conference}, {ISWC} 2005, {Galway}, {Ireland}, {November} 6-10, 2005 ; proceedings},
	isbn = {978-3-540-29754-3},
	shorttitle = {The {Semantic} {Web} - {ISWC} 2005},
	language = {eng},
	number = {3729},
	publisher = {Springer},
	editor = {Gil, Yolanda and Motta, Enrico and Benjamins, V. Richard and Musen, Mark A. and ISWC},
	year = {2005},
	note = {OCLC: 255038614}
}

@inproceedings{gao_asking_2013,
	address = {San Jose, CA},
	title = {Asking {Spatial} {Questions} to {Identify} {GIS} {Functionality}},
	isbn = {978-0-7695-5012-1},
	url = {https://ieeexplore.ieee.org/document/6602049/},
	doi = {10.1109/COMGEO.2013.18},
	abstract = {Current desktop-GIS software cannot answer users’ spatial questions directly. The GIS functionality is hard to identify and use without speciﬁc training of GIS skills because of the complex hierarchical organization and the gap between users’ spatial thinking and systems’ implement descriptions. In order to bridge this gap, we propose a semantic framework for designing a question-based user interface that integrates different levels of ontologies (spatial concept ontology, domain ontology and task ontology) to guide the process of extracting the core spatial concepts and translating them into a set of equivalent computational or operational GIS tasks. We also list some typical spatial questions that might be posed for spatial analysis and computation. The principle introduced in this paper could be applied not only to desktop-GIS software but also to web map services. The semantic framework would be useful to enhance the ability of spatial reasoning in web search engines (e.g. Google semantic search) and answering questions in locationbased services as well (e.g. iPhone Siri assistant).},
	language = {en},
	urldate = {2019-05-27},
	booktitle = {2013 {Fourth} {International} {Conference} on {Computing} for {Geospatial} {Research} and {Application}},
	publisher = {IEEE},
	author = {Gao, Song and Goodchild, Michael F.},
	month = jul,
	year = {2013},
	pages = {106--110}
}

@article{scheider_why_2017,
	title = {Why good data analysts need to be critical synthesists. {Determining} the role of semantics in data analysis},
	volume = {72},
	issn = {0167739X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X17303047},
	doi = {10.1016/j.future.2017.02.046},
	abstract = {In this article, we critically examine the role of semantic technology in data driven analysis. We explain why learning from data is more than just analyzing data, including also a number of essential synthetic parts that suggest a revision of George Box’s model of data analysis in statistics. We review arguments from statistical learning under uncertainty, workflow reproducibility, as well as from philosophy of science, and propose an alternative, synthetic learning model that takes into account semantic conflicts, observation, biased model and data selection, as well as interpretation into background knowledge. The model highlights and clarifies the different roles that semantic technology may have in fostering reproduction and reuse of data analysis across communities of practice under the conditions of informational uncertainty. We also investigate the role of semantic technology in current analysis and workflow tools, compare it with the requirements of our model, and conclude with a roadmap of 8 challenging research problems which currently seem largely unaddressed.},
	language = {en},
	urldate = {2019-05-27},
	journal = {Future Generation Computer Systems},
	author = {Scheider, Simon and Ostermann, Frank O. and Adams, Benjamin},
	month = jul,
	year = {2017},
	pages = {11--22}
}

@article{gigerenzer_homo_2009,
	title = {Homo {Heuristicus}: {Why} {Biased} {Minds} {Make} {Better} {Inferences}},
	volume = {1},
	issn = {17568757, 17568765},
	shorttitle = {Homo {Heuristicus}},
	url = {http://doi.wiley.com/10.1111/j.1756-8765.2008.01006.x},
	doi = {10.1111/j.1756-8765.2008.01006.x},
	abstract = {Heuristics are efﬁcient cognitive processes that ignore information. In contrast to the widely held view that less processing reduces accuracy, the study of heuristics shows that less information, computation, and time can in fact improve accuracy. We review the major progress made so far: (a) the discovery of less-is-more effects; (b) the study of the ecological rationality of heuristics, which examines in which environments a given strategy succeeds or fails, and why; (c) an advancement from vague labels to computational models of heuristics; (d) the development of a systematic theory of heuristics that identiﬁes their building blocks and the evolved capacities they exploit, and views the cognitive system as relying on an ‘‘adaptive toolbox;’’ and (e) the development of an empirical methodology that accounts for individual differences, conducts competitive tests, and has provided evidence for people’s adaptive use of heuristics. Homo heuristicus has a biased mind and ignores part of the available information, yet a biased mind can handle uncertainty more efﬁciently and robustly than an unbiased mind relying on more resource-intensive and general-purpose processing strategies.},
	language = {en},
	number = {1},
	urldate = {2019-05-27},
	journal = {Topics in Cognitive Science},
	author = {Gigerenzer, Gerd and Brighton, Henry},
	month = jan,
	year = {2009},
	pages = {107--143}
}

@article{dong_language_2016,
	title = {Language to {Logical} {Form} with {Neural} {Attention}},
	url = {http://arxiv.org/abs/1601.01280},
	abstract = {Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domainor representation-speciﬁc. In this paper we present a general method based on an attention-enhanced encoder-decoder model. We encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations.},
	language = {en},
	urldate = {2019-05-27},
	journal = {arXiv:1601.01280 [cs]},
	author = {Dong, Li and Lapata, Mirella},
	month = jan,
	year = {2016},
	note = {arXiv: 1601.01280},
	keywords = {Computer Science - Computation and Language}
}

@inproceedings{kasalica_automated_2018,
	address = {Amsterdam},
	title = {Automated composition of scientific workflows: {A} case study on geographic data manipulation},
	isbn = {978-1-5386-9156-4},
	shorttitle = {Automated composition of scientific workflows},
	url = {https://ieeexplore.ieee.org/document/8588718/},
	doi = {10.1109/eScience.2018.00099},
	language = {en},
	urldate = {2019-05-28},
	booktitle = {2018 {IEEE} 14th {International} {Conference} on e-{Science} (e-{Science})},
	publisher = {IEEE},
	author = {Kasalica, Vedran and Lamprecht, Anna-Lena},
	month = oct,
	year = {2018},
	pages = {362--363}
}

@article{rajpurkar_know_2018,
	title = {Know {What} {You} {Don}'t {Know}: {Unanswerable} {Questions} for {SQuAD}},
	shorttitle = {Know {What} {You} {Don}'t {Know}},
	url = {http://arxiv.org/abs/1806.03822},
	abstract = {Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86\% F1 on SQuAD 1.1 achieves only 66\% F1 on SQuAD 2.0.},
	language = {en},
	urldate = {2019-06-13},
	journal = {arXiv:1806.03822 [cs]},
	author = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.03822},
	keywords = {Computer Science - Computation and Language}
}

@article{neis_street_2011,
	title = {The {Street} {Network} {Evolution} of {Crowdsourced} {Maps}: {OpenStreetMap} in {Germany} 2007–2011},
	volume = {4},
	issn = {1999-5903},
	shorttitle = {The {Street} {Network} {Evolution} of {Crowdsourced} {Maps}},
	url = {http://www.mdpi.com/1999-5903/4/1/1},
	doi = {10.3390/fi4010001},
	abstract = {The OpenStreetMap (OSM) project is a prime example in the field of Volunteered Geographic Information (VGI). Worldwide, several hundred thousand people are currently contributing information to the ―free‖ geodatabase. However, the data contributions show a geographically heterogeneous pattern around the globe. Germany counts as one of the most active countries in OSM; thus, the German street network has undergone an extensive development in recent years. The question that remains is this: How does the street network perform in a relative comparison with a commercial dataset? By means of a variety of studies, we show that the difference between the OSM street network for car navigation in Germany and a comparable proprietary dataset was only 9\% in June 2011. The results of our analysis regarding the entire street network showed that OSM even exceeds the information provided by the proprietary dataset by 27\%. Further analyses show on what scale errors can be reckoned with in the topology of the street network, and the completeness of turn restrictions and street name information. In addition to the analyses conducted over the past few years, projections have additionally been made about the point in time by which the OSM dataset for Germany can be considered ―complete‖ in relative comparison to a commercial dataset.},
	language = {en},
	number = {1},
	urldate = {2019-06-14},
	journal = {Future Internet},
	author = {Neis, Pascal and Zielstra, Dennis and Zipf, Alexander},
	month = dec,
	year = {2011},
	keywords = {osm},
	pages = {1--21}
}

@book{noauthor_mapping_2017,
	title = {Mapping and the {Citizen} {Sensor}},
	publisher = {Ubiquity Press Ltd.},
	year = {2017}
}

@incollection{mooney_review_2017,
	title = {A {Review} of {OpenStreetMap} {Data}},
	booktitle = {Mapping and the {Citizen} {Sensor}},
	author = {Mooney, Peter and Minghini, Marco},
	year = {2017},
	keywords = {osm}
}

@article{kalantari_geospatial_2014,
	title = {Geospatial {Metadata} 2.0 – {An} approach for {Volunteered} {Geographic} {Information}},
	volume = {48},
	issn = {01989715},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0198971514000684},
	doi = {10.1016/j.compenvurbsys.2014.06.005},
	abstract = {There has been greater tendency towards embracing the potential of the Web 2.0 in knowledge creation with user contributions becoming signiﬁcantly important in the development of open data such as Volunteered Geographic Information (VGI). An increasing number of volunteers which add value to geospatial data require effective ways of organising and providing access to value-added or newly created data. Metadata records are often unavailable for VGI, making it problematic for users to discover data in the VGI system. This paper discusses potential approaches that can be used to create metadata for VGI. This includes Linked Data, professionally created metadata and metadata created by volunteers. The paper then discusses the shortcomings of these approaches and proposes an unconventional alternative, Geospatial Metadata 2.0. This approach involves VGI users in the creation of metadata, and builds on folksonomies created by them. The paper presents the design and implementation of this idea in a prototype system along with an assessment result. The implementation includes Geospatial Metadata 2.0 addons in Geonetwork, and the assessment beneﬁts from the input of metadata experts worldwide. The assessment of the beneﬁts results indicate such an approach of metadata creation is promising and has the potential to be employed in VGI systems.},
	language = {en},
	urldate = {2019-06-19},
	journal = {Computers, Environment and Urban Systems},
	author = {Kalantari, Mohsen and Rajabifard, Abbas and Olfat, Hamed and Williamson, Ian},
	month = nov,
	year = {2014},
	pages = {35--48}
}

@incollection{kyriakidis_place_2020,
	address = {Cham},
	title = {Place {Questions} and {Human}-{Generated} {Answers}: {A} {Data} {Analysis} {Approach}},
	isbn = {978-3-030-14744-0 978-3-030-14745-7},
	shorttitle = {Place {Questions} and {Human}-{Generated} {Answers}},
	url = {http://link.springer.com/10.1007/978-3-030-14745-7_1},
	abstract = {This paper investigates place-related questions submitted to search systems and their human-generated answers. Place-based search is motivated by the need to identify places matching some criteria, to identify them in space or relative to other places, or to characterize the qualities of such places. Human place-related questions have thus far been insuﬃciently studied and diﬀer strongly from typical keyword queries. They thus challenge today’s search engines providing only rudimentary geographic information retrieval support. We undertake an analysis of the patterns in place-based questions using a large-scale dataset of questions/answers, MS MARCO V2.1. The results of this study reveal patterns that can inform the design of conversational search systems and in-situ assistance systems, such as autonomous vehicles.},
	language = {en},
	urldate = {2019-06-21},
	booktitle = {Geospatial {Technologies} for {Local} and {Regional} {Development}},
	publisher = {Springer International Publishing},
	author = {Hamzei, Ehsan and Li, Haonan and Vasardani, Maria and Baldwin, Timothy and Winter, Stephan and Tomko, Martin},
	editor = {Kyriakidis, Phaedon and Hadjimitsis, Diofantos and Skarlatos, Dimitrios and Mansourian, Ali},
	year = {2020},
	doi = {10.1007/978-3-030-14745-7_1},
	pages = {3--19}
}

@incollection{kyriakidis_relaxing_2020,
	address = {Cham},
	title = {Relaxing {Unanswerable} {Geographic} {Questions} {Using} {A} {Spatially} {Explicit} {Knowledge} {Graph} {Embedding} {Model}},
	isbn = {978-3-030-14744-0 978-3-030-14745-7},
	url = {http://link.springer.com/10.1007/978-3-030-14745-7_2},
	abstract = {Recent years have witnessed a rapid increase in Question Answering (QA) research and products in both academic and industry. However, geographic question answering remained nearly untouched although geographic questions account for a substantial part of daily communication. Compared to general QA systems, geographic QA has its own uniqueness, one of which can be seen during the process of handling unanswerable questions. Since users typically focus on the geographic constraints when they ask questions, if the question is unanswerable based on the knowledge base used by a QA system, users should be provided with a relaxed query which takes distance decay into account during the query relaxation and rewriting process. In this work, we present a spatially explicit translational knowledge graph embedding model called TransGeo which utilizes an edge-weighted PageRank and sampling strategy to encode the distance decay into the embedding model training process. This embedding model is further applied to relax and rewrite unanswerable geographic questions. We carry out two evaluation tasks: link prediction as well as query relaxation/rewriting for an approximate answer prediction task. A geographic knowledge graph training/testing dataset, DB18, as well as an unanswerable geographic query dataset, GeoUQ, are constructed. Compared to four other baseline models, our TransGeo model shows substantial advantages in both tasks.},
	language = {en},
	urldate = {2019-06-21},
	booktitle = {Geospatial {Technologies} for {Local} and {Regional} {Development}},
	publisher = {Springer International Publishing},
	author = {Mai, Gengchen and Yan, Bo and Janowicz, Krzysztof and Zhu, Rui},
	editor = {Kyriakidis, Phaedon and Hadjimitsis, Diofantos and Skarlatos, Dimitrios and Mansourian, Ali},
	year = {2020},
	doi = {10.1007/978-3-030-14745-7_2},
	pages = {21--39}
}

@article{bundy_solving_2013,
	title = {Solving {Guesstimation} {Problems} {Using} the {Semantic} {Web}: {Four} {Lessons} from an {Application}},
	abstract = {Abstract. We draw on our experience of implementing a semi-automated guesstimation application of the Semantic Web, GORT, to draw four lessons, which we claim are of general applicability. These are: 1. Inference can unleash the Semantic Web: The full power of the web will only be realised when we can use it to infer new knowledge from old. 2. The Semantic Web does not constrain the inference mechanisms: Since we must anyway curate the knowledge we extract from the web, we can take the opportunity to translate it into what ever representational formalism is most appropriate for our application. This also enables the use of whatever inference mechanism is most appropriate. 3. Curation must be dynamic: Static curation is not only infeasible due to the size and growth rate of the Semantic Web, but curation must be application-speciﬁc. 4. Own up to uncertainty: Since the Semantic Web is, by design, uncontrolled, the accuracy of knowledge extracted from it cannot be guaranteed. The resulting uncertainty must not be hidden from the user, but must be made manifest.},
	language = {en},
	author = {Bundy, Alan and Sasnauskas, Gintautas and Chan, Michael},
	year = {2013},
	pages = {15}
}

@incollection{mansourian_introducing_2018,
	address = {Cham},
	title = {Introducing {Spatial} {Variability} to the {Impact} {Significance} {Assessment}},
	isbn = {978-3-319-78207-2 978-3-319-78208-9},
	url = {http://link.springer.com/10.1007/978-3-319-78208-9_10},
	abstract = {The concept of Circular Economy has gained momentum during the last decade. Yet unsustainable circular systems can also create unintended social, economic and environmental damage. Sustainability is highly dependent on a system’s geographical context, such as location of resources, cultural acceptance, economic, environmental and transport geography. While in some cases an impact of the proposed change may be considered equally signiﬁcant under all circumstances (e.g. increase of carbon emissions as a main contributor to the global climate change), many impacts may change both their direction and the extent of signiﬁcance dependent on their context (e.g. land consumption may be positively evaluated if applied to abandoned territories or negatively if a forest needs to be sacriﬁced). The geographical context, (i.e. its sensitivity, vulnerability or potential) is commonly assessed by Spatial Decision Support Systems. However, currently those systems typically do not perform an actual impact assessment as impact characteristics stay constant regardless of location. Likewise, relevant Impact Assessment methods, although gradually becoming more spatial, assume their context as invariable. As a consequence, impact signiﬁcance so far is also a spatially unvarying concept. However, current technological developments allow to rapidly record, analyse and visualise spatial data. This article introduces the concept of spatially varying impact signiﬁcance assessment, by reviewing its current deﬁnitions in literature, and analysing to what extent the concept is applied in existing assessment methods. It concludes with a formulation of spatially varying impact signiﬁcance assessment for innovation in the ﬁeld of impact assessment.},
	language = {en},
	urldate = {2019-06-21},
	booktitle = {Geospatial {Technologies} for {All}},
	publisher = {Springer International Publishing},
	author = {Sileryte, Rusne and Gil, Jorge and Wandl, Alexander and van Timmeren, Arjan},
	editor = {Mansourian, Ali and Pilesjö, Petter and Harrie, Lars and van Lammeren, Ron},
	year = {2018},
	doi = {10.1007/978-3-319-78208-9_10},
	pages = {189--209}
}

@incollection{kyriakidis_evaluating_2020,
	address = {Cham},
	title = {Evaluating the {Effectiveness} of {Embeddings} in {Representing} the {Structure} of {Geospatial} {Ontologies}},
	isbn = {978-3-030-14744-0 978-3-030-14745-7},
	url = {http://link.springer.com/10.1007/978-3-030-14745-7_3},
	abstract = {Nowadays word embeddings are used for many natural language processing (NLP) tasks thanks to their ability of capturing the semantic relations between words.Word embeddings have been mostly used to solve traditional NLP problems, such as question answering, textual entailment and sentiment analysis. This work proposes a new way of thinking about word embeddings that exploits them in order to represent geographical knowledge (e.g., geographical ontologies). We also propose metrics for evaluating the eﬀectiveness of an embedding with respect to the ontological structure on which it is created both in an absolute way and with reference to its application within geolocation algorithms.},
	language = {en},
	urldate = {2019-06-21},
	booktitle = {Geospatial {Technologies} for {Local} and {Regional} {Development}},
	publisher = {Springer International Publishing},
	author = {Dassereto, Federico and Di Rocco, Laura and Guerrini, Giovanna and Bertolotto, Michela},
	editor = {Kyriakidis, Phaedon and Hadjimitsis, Diofantos and Skarlatos, Dimitrios and Mansourian, Ali},
	year = {2020},
	doi = {10.1007/978-3-030-14745-7_3},
	pages = {41--57}
}

@book{hitzler_ontology_2016,
	address = {Amsterdam Berlin},
	series = {Studies on the semantic web},
	title = {Ontology engineering with ontology design patterns: foundations and applications},
	isbn = {978-3-89838-715-6 978-1-61499-675-0 978-1-61499-676-7},
	shorttitle = {Ontology engineering with ontology design patterns},
	language = {en},
	number = {25},
	publisher = {IOS Press},
	editor = {Hitzler, Pascal and Gangemi, Aldo and Janowicz, Krzysztof and Krisnadhi, Adila and Presutti, Valentina},
	year = {2016},
	note = {OCLC: 959575811}
}

@article{donoho_50_2017,
	title = {50 {Years} of {Data} {Science}},
	volume = {26},
	issn = {1061-8600, 1537-2715},
	url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1384734},
	doi = {10.1080/10618600.2017.1384734},
	abstract = {More than 50 years ago, John Tukey called for a reformation of academic statistics. In ‘The Future of Data Analysis’, he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or ‘data analysis’. Ten to twenty years ago, John Chambers, Bill Cleveland and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland even suggested the catchy name “Data Science” for his envisioned ﬁeld.},
	language = {en},
	number = {4},
	urldate = {2019-07-01},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Donoho, David},
	month = oct,
	year = {2017},
	pages = {745--766}
}

@incollection{goos_people_1992,
	address = {Berlin, Heidelberg},
	title = {People manipulate objects (but cultivate fields): {Beyond} the raster-vector debate in {GIS}},
	volume = {639},
	isbn = {978-3-540-55966-5 978-3-540-47333-6},
	shorttitle = {People manipulate objects (but cultivate fields)},
	url = {http://link.springer.com/10.1007/3-540-55966-3_3},
	abstract = {The ongoing debate in GIS regarding the relative merits of vector versus raster representations of spatial information is usually couched in technical terms. Yet the technical question of the most appropriate data structure begs the philosophical question of the most appropriate conceptualization of geographic space. The paper confronts this latter question in the context of the opposition between the "object" and "field" views of space. I suggest that GIS can turn a rather dry debate into a source of insights regarding the nature of its subject matter by learning from how people actually experience and deal with the geographic world. Human cognition indeed appears to make use of both the object and field views, but at different geographic scales, and for different purposes. These observations suggest a list of desiderata for the next round of thinking about spatial representation in GIS.},
	language = {en},
	urldate = {2019-07-03},
	booktitle = {Theories and {Methods} of {Spatio}-{Temporal} {Reasoning} in {Geographic} {Space}},
	publisher = {Springer Berlin Heidelberg},
	author = {Couclelis, Helen},
	editor = {Goos, G. and Hartmanis, J. and Frank, A. U. and Campari, I. and Formentini, U.},
	year = {1992},
	doi = {10.1007/3-540-55966-3_3},
	keywords = {gim},
	pages = {65--77}
}

@misc{steffen_module_1993,
	title = {Module {Configuration} by {Minimal} {Model} {Construction}},
	author = {Steffen, Bernhard and Freitag, Burkhard},
	year = {1993}
}

@article{rosenfeld_continuous_1986,
	title = {‘{Continuous}’ functions on digital pictures},
	volume = {4},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0167865586900176},
	doi = {10.1016/0167-8655(86)90017-6},
	abstract = {The epsilon-delta definition of continuity has a natural analog for functions that take lattice points into lattice points. It turns out that a function f is 'continuous' if and only if it takes neighbors into neighbors, i.e., if Q is a neighbor of P, then f(Q)=f(P) or is a neighbor off(P) (diagonal neighbors not allowed). Some basic properties of such 'continuous' functions are established. In particular, we show that a 'continuous' function from a finite block of lattice points into itself has an 'almost-fixed' point P such that f(P) is a neighbor of P (diagonal neighbors allowed). We also show that a function is one-to-one and continuous if and only if it is a combination of translations, rotations by multiples of 90 °, or reflections in a horizontal, vertical, or diagonal line.},
	language = {en},
	number = {3},
	urldate = {2019-07-05},
	journal = {Pattern Recognition Letters},
	author = {Rosenfeld, Azriel},
	month = jul,
	year = {1986},
	pages = {177--184}
}

@article{spyns_data_2002,
	title = {Data modelling versus ontology engineering},
	volume = {31},
	issn = {01635808},
	url = {http://portal.acm.org/citation.cfm?doid=637411.637413},
	doi = {10.1145/637411.637413},
	abstract = {Ontologies in current computer science parlance are computer based resources that represent agreed domain semantics. Unlike data models, the fundamental asset of ontologies is their relative independence of particular applications, i.e. an ontology consists of relatively generic knowledge that can be reused by different kinds of applications/tasks. The first part of this paper concerns some aspects that help to understand the differences and similarities between ontologies and data models. In the second part we present an ontology engineering framework that supports and favours the genericity of an ontology. We introduce the DOGMA ontology engineering approach that separates “atomic” conceptual relations from “predicative” domain rules. A DOGMA ontology consists of an ontology base that holds sets of intuitive context-specific conceptual relations and a layer of “relatively generic” ontological commitments that hold the domain rules. This constitutes what we shall call the double articulation of a DOGMA ontology 1.},
	language = {en},
	number = {4},
	urldate = {2019-07-05},
	journal = {ACM SIGMOD Record},
	author = {Spyns, Peter and Meersman, Robert and Jarrar, Mustafa},
	month = dec,
	year = {2002},
	keywords = {semantics},
	pages = {12}
}

@article{haklay_how_2010,
	title = {How {Good} is {Volunteered} {Geographical} {Information}? {A} {Comparative} {Study} of {OpenStreetMap} and {Ordnance} {Survey} {Datasets}},
	volume = {37},
	issn = {0265-8135, 1472-3417},
	shorttitle = {How {Good} is {Volunteered} {Geographical} {Information}?},
	url = {http://journals.sagepub.com/doi/10.1068/b35097},
	doi = {10.1068/b35097},
	abstract = {Within the framework of Web 2.0 mapping applications, the most striking example of a geographical application is the OpenStreetMap (OSM) project. OSM aims to create a free digital map of the world and is implemented through the engagement of participants in a mode similar to software development in Open Source projects. The information is collected by many participants, collated on a central database, and distributed in multiple digital formats through the World Wide Web. This type of information was termed `Volunteered Geographical Information' (VGI) by Goodchild, 2007. However, to date there has been no systematic analysis of the quality of VGI. This study aims to fill this gap by analysing OSM information. The examination focuses on analysis of its quality through a comparison with Ordnance Survey (OS) datasets. The analysis focuses on London and England, since OSM started in London in August 2004 and therefore the study of these geographies provides the best understanding of the achievements and difficulties of VGI. The analysis shows that OSM information can be fairly accurate: on average within about 6 m of the position recorded by the OS, and with approximately 80\% overlap of motorway objects between the two datasets. In the space of four years, OSM has captured about 29\% of the area of England, of which approximately 24\% are digitised lines without a complete set of attributes. The paper concludes with a discussion of the implications of the findings to the study of VGI as well as suggesting future research directions.},
	language = {en},
	number = {4},
	urldate = {2019-07-08},
	journal = {Environment and Planning B: Planning and Design},
	author = {Haklay, Mordechai},
	month = aug,
	year = {2010},
	pages = {682--703}
}

@article{lawrence_nlmaps:_nodate,
	title = {{NLmaps}: {A} {Natural} {Language} {Interface} to {Query} {OpenStreetMap}},
	abstract = {We present a Natural Language Interface (nlmaps.cl.uni-heidelberg.de) to query OpenStreetMap. Natural language questions about geographical facts are parsed into database queries that can be executed against the OpenStreetMap (OSM) database. After parsing the question, the system provides a text-based answer as well as an interactive map with all points of interest and their relevant information marked. Additionally, we provide several options for users to give feedback after a question has been parsed.},
	language = {en},
	author = {Lawrence, Carolin and Riezler, Stefan},
	pages = {5}
}

@techreport{butler_geojson_2016,
	title = {The {GeoJSON} {Format}},
	url = {https://www.rfc-editor.org/info/rfc7946},
	abstract = {GeoJSON is a geospatial data interchange format based on JavaScript Object Notation (JSON). It defines several types of JSON objects and the manner in which they are combined to represent data about geographic features, their properties, and their spatial extents. GeoJSON uses a geographic coordinate reference system, World Geodetic System 1984, and units of decimal degrees.},
	language = {en},
	number = {RFC7946},
	urldate = {2019-07-09},
	institution = {RFC Editor},
	author = {Butler, H. and Daly, M. and Doyle, A. and Gillies, S. and Hagen, S. and Schaub, T.},
	month = aug,
	year = {2016},
	doi = {10.17487/RFC7946},
	pages = {RFC7946}
}

@article{schultz_open_2017,
	title = {Open land cover from {OpenStreetMap} and remote sensing},
	volume = {63},
	issn = {03032434},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0303243417301605},
	doi = {10.1016/j.jag.2017.07.014},
	abstract = {OpenStreetMap (OSM) tags were used to produce a global Open Land Cover (OLC) product with fractional data gaps available at osmlanduse.org. Data gaps in the global OLC map were ﬁlled for a case study in Heidelberg, Germany using free remote sensing data, which resulted in a land cover (LC) prototype with complete coverage in this area. Sixty tags in the OSM were used to allocate a Corine Land Cover (CLC) level 2 land use classiﬁcation to 91.8\% of the study area, and the remaining gaps were ﬁlled with remote sensing data. For this case study, complete are coverage OLC overall accuracy was estimated 87\%, which performed better than the CLC product (81\% overall accuracy) of 2012. Spatial thematic overlap for the two products was 84\%. OLC was in large parts found to be more detailed than CLC, particularly when LC patterns were heterogeneous, and outperformed CLC in the classiﬁcation of 12 of the 14 classes. Our OLC product represented data created in diﬀerent periods; 53\% of the area was 2011–2016, and 46\% of the area was representative of 2016–2017.},
	language = {en},
	urldate = {2019-07-11},
	journal = {International Journal of Applied Earth Observation and Geoinformation},
	author = {Schultz, Michael and Voss, Janek and Auer, Michael and Carter, Sarah and Zipf, Alexander},
	month = dec,
	year = {2017},
	keywords = {osm},
	pages = {206--213}
}

@article{auer_towards_2018,
	title = {Towards {Using} the {Potential} of {OpenStreetMap} {History} for {Disaster} {Activation} {Monitoring}},
	abstract = {Over the last couple of years, the growing OpenStreetMap (OSM) database repeatedly proved its potential for various use cases, including disaster management. Disaster mapping activations show increasing numbers of contributions, but oftentimes raise questions related to the quality of the provided Volunteered Geographic Information. In order to better monitor and understand OSM mapping and data quality, we developed the ohsome software platform that applies big data technology to OSM full history data. OSM full history data monitoring allows detailed analyses of the OSM data evolution and the detection of remarkable patterns over time. This paper illustrates the speciﬁc potential of our platform for disaster activations by means of two case studies. Initial results demonstrate that our ﬂexible and scalable platform structure enables fast and easy information extraction and supports mapping processes and data quality assurance.},
	language = {en},
	author = {Auer, Michael and Fendrich, Sascha and Kowatsch, Fabian and Raifer, Martin and Troilo, Rafael and Eckle, Melanie and Griesbaum, Luisa and Marx, Sabrina and Schott, Moritz and Zipf, Alexander},
	year = {2018},
	pages = {10}
}

@techreport{peuquet_ontology_nodate,
	title = {The {Ontology} of {Fields}},
	language = {en},
	author = {Peuquet, Donna and Smith, Barry and Brogaard, Berit}
}

@article{kuhn_ontologies_2001,
	title = {Ontologies in support of activities in geographical space},
	volume = {15},
	issn = {1365-8816, 1362-3087},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13658810110061180},
	doi = {10.1080/13658810110061180},
	abstract = {A method is proposed to derive ontologies of geographical domains from natural language texts that describe human activities. Through its textual grounding, the method addresses the issue of where to take the contents of ontologies from. Through its focus on actions aŒorded by domain objects, it establishes a criterion for selecting the contents. The actions are organized into a hierarchical theory of human activities in the domain. Using an analysis of the German tra c code as a case study, the paper demonstrates the informal parts of the process to derive such ontologies.},
	language = {en},
	number = {7},
	urldate = {2019-07-26},
	journal = {International Journal of Geographical Information Science},
	author = {Kuhn, Werner},
	month = oct,
	year = {2001},
	pages = {613--631}
}

@incollection{goos_specifying_1995,
	address = {Berlin, Heidelberg},
	title = {Specifying open {GIS} with functional languages},
	volume = {951},
	isbn = {978-3-540-60159-3 978-3-540-49536-9},
	url = {http://link.springer.com/10.1007/3-540-60159-7_12},
	abstract = {The concept of Open GIS depends on precise definitions of data, operations and interfaces. This paper argues for the use of functional programming languages as specification and prototyping tools for Open GIS components. It shows how functional programming languages fulfill the key requirements for formal specification languages and allow for rapid prototyping in addition. So far, it has never been possible to integrate specification and prototyping in a single, easy to use environment. Most existing specification methods lack appropriate tools for checking and prototyping, while existing tools lack either sound semantics or usability or both.},
	language = {en},
	urldate = {2019-07-26},
	booktitle = {Advances in {Spatial} {Databases}},
	publisher = {Springer Berlin Heidelberg},
	author = {Frank, Andrew U. and Kuhn, Werner},
	editor = {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan and Egenhofer, Max J. and Herring, John R.},
	year = {1995},
	doi = {10.1007/3-540-60159-7_12},
	pages = {184--195}
}

@incollection{goodchild_specification_1999,
	address = {Boston, MA},
	title = {A {Specification} {Language} for {Interoperable} {GIS}},
	isbn = {978-1-4613-7363-6 978-1-4615-5189-8},
	url = {http://link.springer.com/10.1007/978-1-4615-5189-8_10},
	abstract = {Model states the types of inputs (“Geometry”) and outputs (“Boolean”) and gives a natural language description of its semantics: Boolean Equal(Geometry) — determines whether or not the passed geometry is spatially equal to the geometry.},
	language = {en},
	urldate = {2019-07-26},
	booktitle = {Interoperating {Geographic} {Information} {Systems}},
	publisher = {Springer US},
	author = {Frank, Andrew U. and Kuhn, Werner},
	editor = {Goodchild, Michael and Egenhofer, Max and Fegeas, Robin and Kottman, Cliff},
	year = {1999},
	doi = {10.1007/978-1-4615-5189-8_10},
	pages = {123--132}
}

@article{yuan_representing_2001,
	title = {Representing {Complex} {Geographic} {Phenomena} in {GIS}},
	volume = {28},
	issn = {1523-0406, 1545-0465},
	url = {http://www.tandfonline.com/doi/abs/10.1559/152304001782173718},
	doi = {10.1559/152304001782173718},
	abstract = {Conventionally, spatial data models have been designed based on either object- or fieldbased conceptualizations of reality. Conceptualization of complex geographic phenomena that have both object- and field-like properties, such as wildfire and precipitation, has not yet been incorporated into GIS data models. To this end, a new conceptual framework is proposed in this research for organizing data about such complex geographic phenomena in a GIS as a hierarchy of events, processes, and states. In this framework, discrete objects are used to show how events and processes progress in space and time, and fields are used to model how states of geographic themes vary in a space-time frame. Precipitation is used to demonstrate the construction and application of the proposed framework with digital precipitation data from April 15 to May 22, 1998, for the state of Oklahoma, U.S.A. With the proposed framework, two sets of algorithms have been developed. One set automatically assembles precipitation events and processes from the data and stores the precipitation data in the hierarchy of events, processes, and states, so that attributes about events, processes, and states are readily available for information query. The other set of algorithms computes information about the spatio-temporal behavior and interaction of events and processes. The proposed approach greatly enhances support for complex spatio-temporal queries on the behavior and relationships of events and processes.},
	language = {en},
	number = {2},
	urldate = {2019-08-14},
	journal = {Cartography and Geographic Information Science},
	author = {Yuan, May},
	month = jan,
	year = {2001},
	pages = {83--96}
}

@inproceedings{paolino_phenomena:_2003,
	address = {New Orleans, Louisiana, USA},
	title = {Phenomena: a visual query language for continuous fields},
	isbn = {978-1-58113-730-9},
	shorttitle = {Phenomena},
	url = {http://portal.acm.org/citation.cfm?doid=956676.956696},
	doi = {10.1145/956676.956696},
	abstract = {In the present paper we introduce a visual query language, Phenomena, able to manage continuous fields, which represent realworld events. In GIS applications, continuous fields represent phenomena related to the environment and its resources. Recently, much attention has been devoted to the field view of geographic phenomena, where the geographic world can be described by a number of variables, each measurable at any point. While objects are distinguished by their dimensions, and can be associated with points, lines, or areas, fields can be distinguished by what varies, and how smoothly. Thus, when dealing with continuous fields, a basic requirement is represented by users’ capability to capture some features of a scenario, by selecting an area of interest and handling the heterogeneous events involved. Phenomena makes this task easy to implement, thanks to a quite intuitive visual representation of both continuous fields and conditions, which involve them. A peculiar feature of the visual language is the use of geometries to select portions of continuous fields, on the basis of spatial conditions. The heterogeneous nature of fields and objects is also reflected in the visualization of query results.},
	language = {en},
	urldate = {2019-08-14},
	booktitle = {Proceedings of the eleventh {ACM} international symposium on {Advances} in geographic information systems  - {GIS} 2003},
	publisher = {ACM Press},
	author = {Paolino, Luca and Tortora, Genoveffa and Sebillo, Monica and Vitiello, Giuliana and Laurini, Robert},
	year = {2003},
	pages = {147--153}
}

@article{guizzardi_representation_nodate,
	title = {On the {Representation} of {Quantities} and their {Parts} in {Conceptual} {Modeling}},
	abstract = {In a series of publications, we have employed ontological theories and principles used to evaluate and improve the quality of conceptual modeling grammars and models. In this article, we continue this work by providing an ontological interpretation and sound modeling guidelines for a traditionally neglected notion in the conceptual modeling literature, namely, the representation of types whose instances are quantities (amounts of matter, masses). Here, we analyze different alternatives for the adequate representation of quantities as well as their parts in conceptual models. Moreover, we advance a number of metamodeling constraints that can be incorporated in a UML 2.0 metamodel extension, thus, allowing for the suitable representation of these notions.},
	language = {en},
	author = {Guizzardi, Giancarlo},
	pages = {14}
}

@misc{hu_geospatial_2017,
	title = {Geospatial {Semantics}},
	author = {Hu, Yingjie},
	year = {2017}
}

@inproceedings{ferres_experiments_2006,
	address = {Not Known},
	title = {Experiments adapting an open-domain question answering system to the geographical domain using scope-based resources},
	isbn = {978-2-9524532-4-0},
	url = {http://portal.acm.org/citation.cfm?doid=1708097.1708111},
	doi = {10.3115/1708097.1708111},
	abstract = {This paper describes an approach to adapt an existing multilingual Open-Domain Question Answering (ODQA) system for factoid questions to a Restricted Domain, the Geographical Domain. The adaptation of this ODQA system involved the modiﬁcation of some components of our system such as: Question Processing, Passage Retrieval and Answer Extraction. The new system uses external resources like GNS Gazetteer for Named Entity (NE) Classiﬁcation and Wikipedia or Google in order to obtain relevant documents for this domain. The system focuses on a Geographical Scope: given a region, or country, and a language we can semi-automatically obtain multilingual geographical resources (e.g. gazetteers, trigger words, groups of place names, etc.) of this scope. The system has been trained and evaluated for Spanish in the scope of the Spanish Geography. The evaluation reveals that the use of scope-based Geographical resources is a good approach to deal with multilingual Geographical Domain Question Answering.},
	language = {en},
	urldate = {2019-08-26},
	booktitle = {Proceedings of the {Workshop} on {Multilingual} {Question} {Answering} - {MLQA} '06},
	publisher = {Association for Computational Linguistics},
	author = {Ferrés, Daniel and Rodríguez, Horacio},
	year = {2006},
	pages = {69}
}

@article{palmer_analytic_2011,
	title = {The analytic potential of scientific data: {Understanding} re-use value},
	volume = {48},
	issn = {00447870},
	shorttitle = {The analytic potential of scientific data},
	url = {http://doi.wiley.com/10.1002/meet.2011.14504801174},
	doi = {10.1002/meet.2011.14504801174},
	abstract = {While problems related to the curation and preservation of scientific data are receiving considerable attention from the information science and digital repository communities, relatively little progress has been made on approaches for evaluating the value of data to inform investment in acquisition, curation, and preservation. Adapting Hjørland’s concept of the “epistemological potential” of documents, we assert that analytic potential, or the value of data for analysis beyond its original use, should guide development of data collections for repositories aimed at supporting research. Three key aspects of the analytic potential of data are identified and discussed: preservation readiness, potential user communities, and fit for purpose. Based on evidence from research from the Data Conservancy initiative, we demonstrate how the analytic potential of data can be determined and applied to build large-scale data collections suited for grand challenge science.},
	language = {en},
	number = {1},
	urldate = {2019-08-28},
	journal = {Proceedings of the American Society for Information Science and Technology},
	author = {Palmer, Carole L. and Weber, Nicholas M. and Cragin, Melissa H.},
	year = {2011},
	pages = {1--10}
}